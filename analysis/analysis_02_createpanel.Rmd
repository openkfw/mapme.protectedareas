---
title: "Panel creation"
author: "Yota"
date: "28 3 2022"
output: workflowr::wflow_html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/shared/datalake/mapme.protectedareas")
```


```{r workspace and packages}
# clean workspace, set options
rm(list=ls())
options(scipen=999)

# get packages
lop <- c("tidyverse", "sf")
newp <- lop[!(lop %in% installed.packages()[,"Package"])]
if(length(newp)) install.packages(newp)
lapply(lop, require, character.only = TRUE)

```

```{r load fcl}
# Timer
start_time <- Sys.time()

#------- Load and prepare fc data -------

# # Forest loss data
# fcl_supported_AND_nonPas <-
#   read_csv("../../datalake/mapme.protectedareas/output/polygon/sampling/fishnets/dec_08/gfw/gfw_10km_all.csv")
# 
# # Select variables
# fcl_data <- fcl_supported_AND_nonPas %>% 
#   select(poly_id,id.x,treatment.x, starts_with("area"), starts_with("loss"))

# Forest loss data
fcl <- read_rds("/datadrive/datalake/mapme.protectedareas/output/matching/matching_frames/full_database.rds") %>%
  select(.assetid,
         starts_with("treecover"),
         starts_with("loss"),
         starts_with("minprec"),
         starts_with("maxprec"),
         starts_with("wetness")) %>%
  select(-starts_with("loss_t3"))

# change variable names to facilitate long format conversion in code below
 colnames(fcl) <-  sub("*_anomaly*", "", colnames(fcl))
 colnames(fcl) <-  sub("*_min*", "", colnames(fcl))
 
# Load link between assetid and WDPA ID
keys_assetid_wdpa <- 
  read_sf("~/shared/datalake/mapme.protectedareas/processing/fishnet/honeycomb_5_sqkm_kfw.gpkg") %>% 
  select(poly_id, WDPAID) %>% 
  rename(".assetid" = "poly_id") %>% 
  st_drop_geometry()
  
```

```{r Panelize PSM data}
# Years with matching frames:
 T_year <- c(2003:2017, 2019)
# T_year <- c(2015)

for (i in T_year) {
  
  # tryCatch({
  
    # Load matched data
    # m_data <-
    #     read_csv(paste0("../../datalake/mapme.protectedareas/output/tabular/regression_input/PSM/ps_matched_data_", i, ".csv"))
    m_data <-
      read_rds(paste0("../../datalake/mapme.protectedareas/output/tabular/regression_input/PSM/psm_matched_data_", i, ".rds")) %>%
      rename("m_treecover" = "treecover",
             "m_loss" = "loss",
             "m_loss_t3" = "loss_t3")
    # change variable names to facilitate long format conversion in code below
    colnames(m_data) <-  sub("*_anomaly*", "", colnames(m_data))
    colnames(m_data) <-  sub("*_min*", "", colnames(m_data))    
 
    # Merge matched data with 
    # merged_data <- 
    #   left_join(m_data, fcl_data,
    #                          by=c("poly_id")) %>% 
    #   pivot_longer(cols = c(starts_with("area") | starts_with("loss")),
    #                names_to = c(".value", "year"),
    #                names_sep = "_") %>% 
    #   select(-id.x, -treatment.x) %>% 
    #   mutate(year_standard = as.numeric(year) - i) %>% 
    #   rename("fc_area" = "area",
    #          "fc_loss" = "loss")
    merged_data <- 
      left_join(m_data, fcl, by=c(".assetid")) %>% 
      pivot_longer(cols = c(starts_with("treecover") | starts_with("loss") | starts_with("minprec") | starts_with("maxprec") | starts_with("wetness")),
                   names_to = c(".value", "year"),
                   names_sep = "_") %>% 
      mutate(year_standard = as.numeric(year) - i) %>% 
      rename("fc_area" = "treecover",
             "fc_loss" = "loss") %>% 
      left_join(., keys_assetid_wdpa,
                by=c(".assetid")) %>% 
      mutate(WDPAID = ifelse(treatment == 0, 9999999999, WDPAID))
        
    ## Export data
    write_csv(merged_data,
              paste0("../../datalake/mapme.protectedareas/output/tabular/regression_input/PSM/psm_matched_panel_", i, ".csv"))

  
  # }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
    
}
```



```{r Panelize CEM data}
# Years with matching frames:
T_year <- c(2003:2017, 2019)
# T_year <- c(2015)
# T_year <- c(2004:2014, 2016, 2019)

for (i in T_year) {
  
  # tryCatch({
  
    # Load matched data
    # m_data <- 
    #     read_csv(paste0("../../datalake/mapme.protectedareas/output/tabular/regression_input/CEM/ce_matched_data_", i, ".csv"))
    m_data <- 
        read_rds(paste0("../../datalake/mapme.protectedareas/output/tabular/regression_input/CEM/cem_matched_data_", i, ".rds")) %>%
      rename("m_treecover" = "treecover",
             "m_loss" = "loss",
             "m_loss_t3" = "loss_t3")
    # change variable names to facilitate long format conversion in code below
    colnames(m_data) <-  sub("*_anomaly*", "", colnames(m_data))
    colnames(m_data) <-  sub("*_min*", "", colnames(m_data))    
    
    # Merge matched data with 
    # merged_data <- 
    #   left_join(m_data, fcl_data,
    #             by=c("poly_id")) %>% 
    #   pivot_longer(cols = c(starts_with("area") | starts_with("loss")),
    #                names_to = c(".value", "year"),
    #                names_sep = "_") %>% 
    #   select(-id.x, -treatment.x) %>% 
    #   mutate(year_standard = as.numeric(year) - i) %>% 
    #   rename("fc_area" = "area",
    #          "fc_loss" = "loss")
    
    merged_data <- 
      left_join(m_data, fcl,
                             by=c(".assetid")) %>% 
      pivot_longer(cols = c(starts_with("treecover") | starts_with("loss") | starts_with("minprec") | starts_with("maxprec") | starts_with("wetness")),
                   names_to = c(".value", "year"),
                   names_sep = "_") %>% 
      mutate(year_standard = as.numeric(year) - i) %>% 
      rename("fc_area" = "treecover",
             "fc_loss" = "loss") %>% 
      left_join(., keys_assetid_wdpa,
                by=c(".assetid")) %>% 
      mutate(WDPAID = ifelse(treatment == 0, 9999999999, WDPAID))
    
    ## Export data
    write_csv(merged_data, 
              paste0("../../datalake/mapme.protectedareas/output/tabular/regression_input/CEM/cem_matched_panel_", i, ".csv"))
  
  # }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
    
}

# Timer
end_time <- Sys.time()

duration <- difftime(end_time, start_time, units='mins')
duration
```
